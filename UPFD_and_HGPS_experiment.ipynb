{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "11xtxBggd4nd",
        "8Lo0V-yTAoUr",
        "cPMfWE75TRmt",
        "QqEneh4wr1c4"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fake News Detection using PyTorch Geometric"
      ],
      "metadata": {
        "id": "jzJPAMwSY65V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and Setup"
      ],
      "metadata": {
        "id": "1Kcc3IMdZBwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random"
      ],
      "metadata": {
        "id": "ghB49ESw61uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "gkg-eLyRT3Of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PyTorch Metrics\n",
        "try:\n",
        "    import torchmetrics\n",
        "except ModuleNotFoundError:\n",
        "    !pip install -q torchmetrics\n",
        "    import torchmetrics"
      ],
      "metadata": {
        "id": "H00IDHTqO-Pg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70de7eb3-5bce-4e6a-c3cc-99246d6db7f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PyTorch Lightning\n",
        "try:\n",
        "    import pytorch_lightning as pl\n",
        "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
        "    !pip install -q pytorch-lightning\n",
        "    import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping"
      ],
      "metadata": {
        "id": "EILT_uAn6miW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef0e2f17-d666-4788-ea62-dd04d9c4d47b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m777.7/777.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Torch geometric\n",
        "try:\n",
        "    import torch_geometric\n",
        "except ModuleNotFoundError:\n",
        "    # Installing torch geometric packages with specific CUDA+PyTorch version.\n",
        "    # See https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html for details\n",
        "    TORCH = torch.__version__.split('+')[0]\n",
        "    CUDA = 'cu' + torch.version.cuda.replace('.','')\n",
        "\n",
        "    !pip install -q pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-{TORCH}+{CUDA}.html\n",
        "    !pip install -q git+https://github.com/rusty1s/pytorch_geometric.git\n",
        "    import torch_geometric\n",
        "import torch_geometric.nn as geom_nn\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.utils import get_laplacian"
      ],
      "metadata": {
        "id": "VsQ6f-duS6BA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "085185bb-93f3-45e6-de81-d7091750b3fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m932.1/932.1 kB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "def set_seed(seed: int = 42) -> None:\n",
        "    pl.seed_everything(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    print(f\"Random seed set as {seed}\")\n",
        "\n",
        "set_seed()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcsvaCdBTsh8",
        "outputId": "de85a388-5991-43ca-ab39-83601ba67783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed set as 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CHECKPOINT_PATH = \"./saved_models/\"\n",
        "DATA_PATH = \"./data\"\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "TmY9InFx67RC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define dataset classes"
      ],
      "metadata": {
        "id": "ZyB3RRbmZD3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import UPFD\n",
        "\n",
        "class UPFDDataModule(pl.LightningDataModule):\n",
        "    def __init__(\n",
        "            self,\n",
        "            batch_size: int = 32,\n",
        "            dataset: str = \"politifact\",\n",
        "            feature: str = \"bert\"\n",
        "        ):\n",
        "        super().__init__()\n",
        "\n",
        "        # this line allows to access init params with 'self.hparams' attribute\n",
        "        self.save_hyperparameters(logger=False)\n",
        "\n",
        "    @property\n",
        "    def num_node_features(self):\n",
        "        return self.data_train.num_node_features\n",
        "\n",
        "    @property\n",
        "    def num_classes(self):\n",
        "        return self.data_train.num_classes\n",
        "\n",
        "    def setup(self, stage: str):\n",
        "        if stage==\"fit\":\n",
        "            self.data_train = UPFD(root=DATA_PATH, name=self.hparams.dataset, feature=self.hparams.feature, split=\"train\")\n",
        "            self.data_val = UPFD(root=DATA_PATH, name=self.hparams.dataset, feature=self.hparams.feature, split=\"val\")\n",
        "\n",
        "        if stage==\"test\":\n",
        "            self.data_test = UPFD(root=DATA_PATH, name=self.hparams.dataset, feature=self.hparams.feature, split=\"test\")\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(dataset=self.data_train, batch_size=self.hparams.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(dataset=self.data_val, batch_size=self.hparams.batch_size)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(dataset=self.data_test, batch_size=self.hparams.batch_size)"
      ],
      "metadata": {
        "id": "3Mj-UK7wuI7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Classifier models"
      ],
      "metadata": {
        "id": "6wYps5H24FoZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### UPFD Model"
      ],
      "metadata": {
        "id": "Gfda9_a3S_fF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UPFDModel(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, c_hidden, c_out, concat, dropout_ratio=0.5, **kwargs):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Dimension of input features\n",
        "            c_hidden - Dimension of hidden features\n",
        "            c_out - Dimension of the output features. Usually number of classes in classification\n",
        "            dp_rate_linear - Dropout rate before the linear layer (usually much higher than inside the GNN)\n",
        "            kwargs - Additional arguments for the graph layers\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.concat = concat\n",
        "        self.model = 'sage'\n",
        "\n",
        "        if self.model == 'gcn':\n",
        "            self.conv1 = geom_nn.GCNConv(c_in, c_hidden)\n",
        "        elif self.model == 'sage':\n",
        "            self.conv1 = geom_nn.SAGEConv(c_in, c_hidden)\n",
        "        elif self.model == 'gat':\n",
        "            self.conv1 = geom_nn.GATConv(c_in, c_hidden)\n",
        "\n",
        "        if self.concat:\n",
        "            self.lin0 = torch.nn.Linear(c_in, c_hidden)\n",
        "            self.lin1 = torch.nn.Linear(c_hidden * 2, c_hidden)\n",
        "\n",
        "        self.lin2 = torch.nn.Linear(c_hidden, c_out)\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index, batch_idx, batch_size):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            x - Input features per node\n",
        "            edge_index - List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
        "            batch_idx - Index of batch element for each node\n",
        "            batch_size - Size of a batch that is used in MixUp\n",
        "            lam - Lambda paratemeter for MixUp\n",
        "        \"\"\"\n",
        "        edge_attr = None\n",
        "\n",
        "        raw_x = x.clone()\n",
        "\n",
        "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
        "        x = geom_nn.global_max_pool (x, batch_idx)\n",
        "\n",
        "        if self.concat:\n",
        "            news = torch.stack([raw_x[(batch_idx == idx).nonzero().squeeze()[0]] for idx in range(batch_size)])\n",
        "            news = F.relu(self.lin0(news))\n",
        "            x = torch.cat([x, news], dim=1)\n",
        "            x = F.relu(self.lin1(x))\n",
        "\n",
        "        x = self.lin2(x)\n",
        "\n",
        "        return x, None"
      ],
      "metadata": {
        "id": "KRtPhumo6UVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP Used in GIN layers"
      ],
      "metadata": {
        "id": "11xtxBggd4nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, c_in, c_hidden, c_out, dropout=0.2):\n",
        "        super(MLP, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=c_in, out_features=c_hidden)\n",
        "        self.fc2 = nn.Linear(in_features=c_hidden, out_features=c_hidden)\n",
        "        self.fc3 = nn.Linear(in_features=c_hidden, out_features=c_out)\n",
        "\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(c_hidden)\n",
        "        self.bn2 = nn.BatchNorm1d(c_hidden)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "NpGwSExj6xtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HPG-SL Pooling"
      ],
      "metadata": {
        "id": "8Lo0V-yTAoUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Function\n",
        "from torch_scatter import scatter_add, scatter_max\n",
        "\n",
        "\n",
        "def scatter_sort(x, batch, fill_value=-1e16):\n",
        "    num_nodes = scatter_add(batch.new_ones(x.size(0)), batch, dim=0)\n",
        "    batch_size, max_num_nodes = num_nodes.size(0), num_nodes.max().item()\n",
        "\n",
        "    cum_num_nodes = torch.cat([num_nodes.new_zeros(1), num_nodes.cumsum(dim=0)[:-1]], dim=0)\n",
        "\n",
        "    index = torch.arange(batch.size(0), dtype=torch.long, device=x.device)\n",
        "    index = (index - cum_num_nodes[batch]) + (batch * max_num_nodes)\n",
        "\n",
        "    dense_x = x.new_full((batch_size * max_num_nodes,), fill_value)\n",
        "    dense_x[index] = x\n",
        "    dense_x = dense_x.view(batch_size, max_num_nodes)\n",
        "\n",
        "    sorted_x, _ = dense_x.sort(dim=-1, descending=True)\n",
        "    cumsum_sorted_x = sorted_x.cumsum(dim=-1)\n",
        "    cumsum_sorted_x = cumsum_sorted_x.view(-1)\n",
        "\n",
        "    sorted_x = sorted_x.view(-1)\n",
        "    filled_index = sorted_x != fill_value\n",
        "\n",
        "    sorted_x = sorted_x[filled_index]\n",
        "    cumsum_sorted_x = cumsum_sorted_x[filled_index]\n",
        "\n",
        "    return sorted_x, cumsum_sorted_x\n",
        "\n",
        "\n",
        "def _make_ix_like(batch):\n",
        "    num_nodes = scatter_add(batch.new_ones(batch.size(0)), batch, dim=0)\n",
        "    idx = [torch.arange(1, i + 1, dtype=torch.long, device=batch.device) for i in num_nodes]\n",
        "    idx = torch.cat(idx, dim=0)\n",
        "\n",
        "    return idx\n",
        "\n",
        "\n",
        "def _threshold_and_support(x, batch):\n",
        "    \"\"\"Sparsemax building block: compute the threshold\n",
        "    Args:\n",
        "        x: input tensor to apply the sparsemax\n",
        "        batch: group indicators\n",
        "    Returns:\n",
        "        the threshold value\n",
        "    \"\"\"\n",
        "    num_nodes = scatter_add(batch.new_ones(x.size(0)), batch, dim=0)\n",
        "    cum_num_nodes = torch.cat([num_nodes.new_zeros(1), num_nodes.cumsum(dim=0)[:-1]], dim=0)\n",
        "\n",
        "    sorted_input, input_cumsum = scatter_sort(x, batch)\n",
        "    input_cumsum = input_cumsum - 1.0\n",
        "    rhos = _make_ix_like(batch).to(x.dtype)\n",
        "    support = rhos * sorted_input > input_cumsum\n",
        "\n",
        "    support_size = scatter_add(support.to(batch.dtype), batch)\n",
        "    # mask invalid index, for example, if batch is not start from 0 or not continuous, it may result in negative index\n",
        "    idx = support_size + cum_num_nodes - 1\n",
        "    mask = idx < 0\n",
        "    idx[mask] = 0\n",
        "    tau = input_cumsum.gather(0, idx)\n",
        "    tau /= support_size.to(x.dtype)\n",
        "\n",
        "    return tau, support_size\n",
        "\n",
        "\n",
        "class SparsemaxFunction(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, batch):\n",
        "        \"\"\"sparsemax: normalizing sparse transform\n",
        "        Parameters:\n",
        "            ctx: context object\n",
        "            x (Tensor): shape (N, )\n",
        "            batch: group indicator\n",
        "        Returns:\n",
        "            output (Tensor): same shape as input\n",
        "        \"\"\"\n",
        "        max_val, _ = scatter_max(x, batch)\n",
        "        x -= max_val[batch]\n",
        "        tau, supp_size = _threshold_and_support(x, batch)\n",
        "        output = torch.clamp(x - tau[batch], min=0)\n",
        "        ctx.save_for_backward(supp_size, output, batch)\n",
        "\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        supp_size, output, batch = ctx.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        grad_input[output == 0] = 0\n",
        "\n",
        "        v_hat = scatter_add(grad_input, batch) / supp_size.to(output.dtype)\n",
        "        grad_input = torch.where(output != 0, grad_input - v_hat[batch], grad_input)\n",
        "\n",
        "        return grad_input, None\n",
        "\n",
        "\n",
        "sparsemax = SparsemaxFunction.apply\n",
        "\n",
        "\n",
        "class Sparsemax(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Sparsemax, self).__init__()\n",
        "\n",
        "    def forward(self, x, batch):\n",
        "        return sparsemax(x, batch)"
      ],
      "metadata": {
        "id": "9IuYEbpZD0DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_scatter import scatter_add\n",
        "from torch_sparse import spspmm, coalesce\n",
        "from torch_geometric.utils import softmax, dense_to_sparse, add_remaining_self_loops\n",
        "from torch.nn import Parameter\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn.pool.connect.filter_edges import filter_adj\n",
        "from torch_geometric.nn.pool.select.topk import topk\n",
        "\n",
        "class TwoHopNeighborhood(object):\n",
        "    def __call__(self, data):\n",
        "        edge_index, edge_attr = data.edge_index, data.edge_attr\n",
        "        n = data.num_nodes\n",
        "\n",
        "        fill = 1e16\n",
        "        value = edge_index.new_full((edge_index.size(1),), fill, dtype=torch.float)\n",
        "\n",
        "        index, value = spspmm(edge_index, value, edge_index, value, n, n, n, True)\n",
        "\n",
        "        edge_index = torch.cat([edge_index, index], dim=1)\n",
        "        if edge_attr is None:\n",
        "            data.edge_index, _ = coalesce(edge_index, None, n, n)\n",
        "        else:\n",
        "            value = value.view(-1, *[1 for _ in range(edge_attr.dim() - 1)])\n",
        "            value = value.expand(-1, *list(edge_attr.size())[1:])\n",
        "            edge_attr = torch.cat([edge_attr, value], dim=0)\n",
        "            data.edge_index, edge_attr = coalesce(edge_index, edge_attr, n, n, op='min')\n",
        "            edge_attr[edge_attr >= fill] = 0\n",
        "            data.edge_attr = edge_attr\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '{}()'.format(self.__class__.__name__)\n",
        "\n",
        "\n",
        "class NodeInformationScore(geom_nn.conv.MessagePassing):\n",
        "    def __init__(self, improved=False, cached=False, **kwargs):\n",
        "        super(NodeInformationScore, self).__init__(aggr='add', **kwargs)\n",
        "\n",
        "        self.improved = improved\n",
        "        self.cached = cached\n",
        "        self.cached_result = None\n",
        "        self.cached_num_edges = None\n",
        "\n",
        "    @staticmethod\n",
        "    def norm(edge_index, num_nodes, edge_weight, dtype=None):\n",
        "        if edge_weight is None:\n",
        "            edge_weight = torch.ones((edge_index.size(1),), dtype=dtype, device=edge_index.device)\n",
        "\n",
        "        row, col = edge_index\n",
        "        deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "\n",
        "        edge_index, edge_weight = add_remaining_self_loops(edge_index, edge_weight, 0, num_nodes)\n",
        "\n",
        "        row, col = edge_index\n",
        "        expand_deg = torch.zeros((edge_weight.size(0),), dtype=dtype, device=edge_index.device)\n",
        "        expand_deg[-num_nodes:] = torch.ones((num_nodes,), dtype=dtype, device=edge_index.device)\n",
        "\n",
        "        return edge_index, expand_deg - deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight):\n",
        "        if self.cached and self.cached_result is not None:\n",
        "            if edge_index.size(1) != self.cached_num_edges:\n",
        "                raise RuntimeError(\n",
        "                    'Cached {} number of edges, but found {}'.format(self.cached_num_edges, edge_index.size(1)))\n",
        "\n",
        "        if not self.cached or self.cached_result is None:\n",
        "            self.cached_num_edges = edge_index.size(1)\n",
        "            edge_index, norm = self.norm(edge_index, x.size(0), edge_weight, x.dtype)\n",
        "            self.cached_result = edge_index, norm\n",
        "\n",
        "        edge_index, norm = self.cached_result\n",
        "\n",
        "        return self.propagate(edge_index, x=x, norm=norm)\n",
        "\n",
        "    def message(self, x_j, norm):\n",
        "        return norm.view(-1, 1) * x_j\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        return aggr_out\n",
        "\n",
        "\n",
        "class HGPSLPool(torch.nn.Module):\n",
        "    def __init__(self, in_channels, ratio=0.8, sample=False, sparse=False, sl=True, lamb=1.0, negative_slop=0.2):\n",
        "        super(HGPSLPool, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.ratio = ratio\n",
        "        self.sample = sample\n",
        "        self.sparse = sparse\n",
        "        self.sl = sl\n",
        "        self.negative_slop = negative_slop\n",
        "        self.lamb = lamb\n",
        "\n",
        "        self.att = Parameter(torch.Tensor(1, self.in_channels * 2))\n",
        "        nn.init.xavier_uniform_(self.att.data)\n",
        "        self.sparse_attention = Sparsemax()\n",
        "        self.neighbor_augment = TwoHopNeighborhood()\n",
        "        self.calc_information_score = NodeInformationScore()\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, batch=None):\n",
        "        if batch is None:\n",
        "            batch = edge_index.new_zeros(x.size(0))\n",
        "\n",
        "        x_information_score = self.calc_information_score(x, edge_index, edge_attr)\n",
        "        score = torch.sum(torch.abs(x_information_score), dim=1)\n",
        "\n",
        "        # Graph Pooling\n",
        "        original_x = x\n",
        "        perm = topk(score, self.ratio, batch)\n",
        "        x = x[perm]\n",
        "        batch = batch[perm]\n",
        "        induced_edge_index, induced_edge_attr = filter_adj(edge_index, edge_attr, perm, num_nodes=score.size(0))\n",
        "\n",
        "        # Discard structure learning layer, directly return\n",
        "        if self.sl is False:\n",
        "            return x, induced_edge_index, induced_edge_attr, batch\n",
        "\n",
        "        # Structure Learning\n",
        "        if self.sample:\n",
        "            # A fast mode for large graphs.\n",
        "            # In large graphs, learning the possible edge weights between each pair of nodes is time consuming.\n",
        "            # To accelerate this process, we sample it's K-Hop neighbors for each node and then learn the\n",
        "            # edge weights between them.\n",
        "            k_hop = 3\n",
        "            if edge_attr is None:\n",
        "                edge_attr = torch.ones((edge_index.size(1),), dtype=torch.float, device=edge_index.device)\n",
        "\n",
        "            hop_data = Data(x=original_x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "            for _ in range(k_hop - 1):\n",
        "                hop_data = self.neighbor_augment(hop_data)\n",
        "            hop_edge_index = hop_data.edge_index\n",
        "            hop_edge_attr = hop_data.edge_attr\n",
        "            new_edge_index, new_edge_attr = filter_adj(hop_edge_index, hop_edge_attr, perm, num_nodes=score.size(0))\n",
        "\n",
        "            new_edge_index, new_edge_attr = add_remaining_self_loops(new_edge_index, new_edge_attr, 0, x.size(0))\n",
        "            row, col = new_edge_index\n",
        "            weights = (torch.cat([x[row], x[col]], dim=1) * self.att).sum(dim=-1)\n",
        "            weights = F.leaky_relu(weights, self.negative_slop) + new_edge_attr * self.lamb\n",
        "            adj = torch.zeros((x.size(0), x.size(0)), dtype=torch.float, device=x.device)\n",
        "            adj[row, col] = weights\n",
        "            new_edge_index, weights = dense_to_sparse(adj)\n",
        "            row, col = new_edge_index\n",
        "            if self.sparse:\n",
        "                new_edge_attr = self.sparse_attention(weights, row)\n",
        "            else:\n",
        "                new_edge_attr = softmax(weights, row, x.size(0))\n",
        "            # filter out zero weight edges\n",
        "            adj[row, col] = new_edge_attr\n",
        "            new_edge_index, new_edge_attr = dense_to_sparse(adj)\n",
        "            # release gpu memory\n",
        "            del adj\n",
        "            torch.cuda.empty_cache()\n",
        "        else:\n",
        "            # Learning the possible edge weights between each pair of nodes in the pooled subgraph, relative slower.\n",
        "            if edge_attr is None:\n",
        "                induced_edge_attr = torch.ones((induced_edge_index.size(1),), dtype=x.dtype,\n",
        "                                               device=induced_edge_index.device)\n",
        "            num_nodes = scatter_add(batch.new_ones(x.size(0)), batch, dim=0)\n",
        "            shift_cum_num_nodes = torch.cat([num_nodes.new_zeros(1), num_nodes.cumsum(dim=0)[:-1]], dim=0)\n",
        "            cum_num_nodes = num_nodes.cumsum(dim=0)\n",
        "            adj = torch.zeros((x.size(0), x.size(0)), dtype=torch.float, device=x.device)\n",
        "            # Construct batch fully connected graph in block diagonal matirx format\n",
        "            for idx_i, idx_j in zip(shift_cum_num_nodes, cum_num_nodes):\n",
        "                adj[idx_i:idx_j, idx_i:idx_j] = 1.0\n",
        "            new_edge_index, _ = dense_to_sparse(adj)\n",
        "            row, col = new_edge_index\n",
        "\n",
        "            weights = (torch.cat([x[row], x[col]], dim=1) * self.att).sum(dim=-1)\n",
        "            weights = F.leaky_relu(weights, self.negative_slop)\n",
        "            adj[row, col] = weights\n",
        "            induced_row, induced_col = induced_edge_index\n",
        "\n",
        "            adj[induced_row, induced_col] += induced_edge_attr * self.lamb\n",
        "            weights = adj[row, col]\n",
        "            if self.sparse:\n",
        "                new_edge_attr = self.sparse_attention(weights, row)\n",
        "            else:\n",
        "                new_edge_attr = softmax(weights, row, x.size(0))\n",
        "            # filter out zero weight edges\n",
        "            adj[row, col] = new_edge_attr\n",
        "            new_edge_index, new_edge_attr = dense_to_sparse(adj)\n",
        "            # release gpu memory\n",
        "            del adj\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        return x, new_edge_index, new_edge_attr, batch"
      ],
      "metadata": {
        "id": "L5f_4RZ1AtqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GCN Lalyer for HGP-SL"
      ],
      "metadata": {
        "id": "cPMfWE75TRmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(geom_nn.conv.MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels, cached=False, bias=True, **kwargs):\n",
        "        super(GCN, self).__init__(aggr='add', **kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.cached = cached\n",
        "        self.cached_result = None\n",
        "        self.cached_num_edges = None\n",
        "\n",
        "        self.weight = Parameter(torch.Tensor(in_channels, out_channels))\n",
        "        nn.init.xavier_uniform_(self.weight.data)\n",
        "\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.Tensor(out_channels))\n",
        "            nn.init.zeros_(self.bias.data)\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.cached_result = None\n",
        "        self.cached_num_edges = None\n",
        "\n",
        "    @staticmethod\n",
        "    def norm(edge_index, num_nodes, edge_weight, dtype=None):\n",
        "        if edge_weight is None:\n",
        "            edge_weight = torch.ones((edge_index.size(1),), dtype=dtype, device=edge_index.device)\n",
        "\n",
        "        row, col = edge_index\n",
        "        deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "\n",
        "        return edge_index, deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight=None):\n",
        "        x = torch.matmul(x, self.weight)\n",
        "\n",
        "        if self.cached and self.cached_result is not None:\n",
        "            if edge_index.size(1) != self.cached_num_edges:\n",
        "                raise RuntimeError(\n",
        "                    'Cached {} number of edges, but found {}'.format(self.cached_num_edges, edge_index.size(1)))\n",
        "\n",
        "        if not self.cached or self.cached_result is None:\n",
        "            self.cached_num_edges = edge_index.size(1)\n",
        "            edge_index, norm = self.norm(edge_index, x.size(0), edge_weight, x.dtype)\n",
        "            self.cached_result = edge_index, norm\n",
        "\n",
        "        edge_index, norm = self.cached_result\n",
        "\n",
        "        return self.propagate(edge_index, x=x, norm=norm)\n",
        "\n",
        "    def message(self, x_j, norm):\n",
        "        return norm.view(-1, 1) * x_j\n",
        "\n",
        "    def update(self, aggr_out):\n",
        "        if self.bias is not None:\n",
        "            aggr_out = aggr_out + self.bias\n",
        "        return aggr_out\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels, self.out_channels)"
      ],
      "metadata": {
        "id": "HeUeUE_NTbkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HGP-SL Model"
      ],
      "metadata": {
        "id": "aw70AKazMnm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HGPSLModel(nn.Module):\n",
        "\n",
        "    def __init__(self, c_in, c_hidden, c_out, conv_layer, concat=False, pooling_ratio=0.8, sample=True, sparse=True, sl=True, lamb=1, dropout_ratio=0.0, **kwargs):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Dimension of input features\n",
        "            c_hidden - Dimension of hidden features\n",
        "            c_out - Dimension of the output features. Usually number of classes in classification\n",
        "            dp_rate_linear - Dropout rate before the linear layer (usually much higher than inside the GNN)\n",
        "            kwargs - Additional arguments for the graph layers\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "        self.concat = concat\n",
        "\n",
        "        if conv_layer == 'gcn':\n",
        "            self.conv1 = geom_nn.GCNConv(c_in, c_hidden)\n",
        "        elif conv_layer == 'sage':\n",
        "            self.conv1 = geom_nn.SAGEConv(c_in, c_hidden)\n",
        "        elif conv_layer == 'gat':\n",
        "            self.conv1 = geom_nn.GATConv(c_in, c_hidden)\n",
        "        elif conv_layer == 'gin':\n",
        "            self.conv1 = geom_nn.GINConv(MLP(c_in, c_hidden, c_hidden, dropout_ratio))\n",
        "\n",
        "        self.conv2 = GCN(c_hidden, c_hidden)\n",
        "        self.conv3 = GCN(c_hidden, c_hidden)\n",
        "\n",
        "        self.pool1 = HGPSLPool(c_hidden, pooling_ratio, sample, sparse, sl, lamb)\n",
        "        self.pool2 = HGPSLPool(c_hidden, pooling_ratio, sample, sparse, sl, lamb)\n",
        "\n",
        "        # Concatenation Layers\n",
        "        if self.concat:\n",
        "            self.lin0 = torch.nn.Linear(c_in, c_hidden)\n",
        "            self.lin1 = torch.nn.Linear(c_hidden * 3, 2 * c_hidden)\n",
        "\n",
        "        self.lin2 = torch.nn.Linear(2 * c_hidden, c_hidden)\n",
        "        self.lin3 = torch.nn.Linear(c_hidden, c_hidden // 2)\n",
        "        self.lin4 = torch.nn.Linear(c_hidden // 2, c_out)\n",
        "\n",
        "\n",
        "    def forward(self, x, edge_index, batch_idx, batch_size):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            x - Input features per node\n",
        "            edge_index - List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
        "            batch_idx - Index of batch element for each node\n",
        "            batch_size - Size of a batch that is used in MixUp\n",
        "            lam - Lambda paratemeter for MixUp\n",
        "        \"\"\"\n",
        "        raw_x = x.clone()\n",
        "        batch_idx_raw = batch_idx\n",
        "        edge_attr = None\n",
        "\n",
        "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
        "        x, edge_index, edge_attr, batch_idx = self.pool1(x, edge_index, edge_attr, batch_idx)\n",
        "        x1 = torch.cat([geom_nn.global_max_pool(x, batch_idx), geom_nn.global_mean_pool(x, batch_idx)], dim=1)\n",
        "\n",
        "        x = F.relu(self.conv2(x, edge_index, edge_attr))\n",
        "        x, edge_index, edge_attr, batch_idx = self.pool2(x, edge_index, edge_attr, batch_idx)\n",
        "        x2 = torch.cat([geom_nn.global_max_pool(x, batch_idx), geom_nn.global_mean_pool(x, batch_idx)], dim=1)\n",
        "\n",
        "        x = F.relu(self.conv3(x, edge_index, edge_attr))\n",
        "        x3 = torch.cat([geom_nn.global_max_pool(x, batch_idx), geom_nn.global_mean_pool(x, batch_idx)], dim=1)\n",
        "\n",
        "        x = F.relu(x1) + F.relu(x2) + F.relu(x3)\n",
        "\n",
        "        if self.concat:\n",
        "            news = torch.stack([raw_x[(batch_idx_raw == idx).nonzero().squeeze()[0]] for idx in range(batch_size)])\n",
        "            news = F.relu(self.lin0(news))\n",
        "            x = torch.cat([x, news], dim=1)\n",
        "            x = F.relu(self.lin1(x))\n",
        "\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = F.dropout(x, p=self.dropout_ratio, training=self.training)\n",
        "        x = F.relu(self.lin3(x))\n",
        "        x = F.dropout(x, p=self.dropout_ratio, training=self.training)\n",
        "        x = self.lin4(x)\n",
        "\n",
        "        return x, None"
      ],
      "metadata": {
        "id": "cMRan1PGMrEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PL Training Module"
      ],
      "metadata": {
        "id": "QqEneh4wr1c4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphLevelGNN(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, model_name, learning_rate, **model_kwargs):\n",
        "        super().__init__()\n",
        "        # Saving hyperparameters\n",
        "        self.save_hyperparameters()\n",
        "        self.lr = learning_rate\n",
        "        self.model_name = model_name\n",
        "\n",
        "        if \"mewis\" in self.model_name.lower():\n",
        "            self.model = MEWISModel(**model_kwargs)\n",
        "        elif \"hgpsl\" in self.model_name.lower():\n",
        "            self.model = HGPSLModel(**model_kwargs)\n",
        "        else:\n",
        "            self.model = UPFDModel(**model_kwargs)\n",
        "\n",
        "        self.loss_module = nn.BCEWithLogitsLoss()\n",
        "        # Accuracy\n",
        "        self.train_acc = torchmetrics.classification.BinaryAccuracy()\n",
        "        self.valid_acc = torchmetrics.classification.BinaryAccuracy()\n",
        "        self.test_acc = torchmetrics.classification.BinaryAccuracy()\n",
        "        self.test_f1 = torchmetrics.classification.BinaryF1Score()\n",
        "        self.test_prec = torchmetrics.classification.BinaryPrecision()\n",
        "        self.test_rec = torchmetrics.classification.BinaryRecall()\n",
        "\n",
        "\n",
        "    def forward(self, data, mode=\"train\"):\n",
        "        x, edge_index, batch_idx, batch_size = data.x, data.edge_index, data.batch, data.batch_size\n",
        "\n",
        "        x, loss_pool = self.model(x, edge_index, batch_idx, batch_size)\n",
        "        x = x.squeeze(dim=-1)\n",
        "\n",
        "        preds = (x > 0).float()\n",
        "        data.y = data.y.float()\n",
        "\n",
        "\n",
        "        if \"mewis\" in self.model_name.lower():\n",
        "            loss = self.loss_module(x, data.y) + 0.01 * loss_pool\n",
        "        else:\n",
        "            loss = self.loss_module(x, data.y)\n",
        "\n",
        "        return loss, preds\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=self.lr, weight_decay=0.001)\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, preds = self.forward(batch, mode=\"train\")\n",
        "        self.log('train_loss', loss, on_step=False, on_epoch=True, batch_size=batch.batch_size)\n",
        "        self.train_acc(preds, batch.y)\n",
        "        self.log('train_acc', self.train_acc, on_step=False, on_epoch=True, batch_size=batch.batch_size)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        _, preds = self.forward(batch,mode=\"val\")\n",
        "        self.valid_acc(preds, batch.y)\n",
        "        self.log('valid_acc', self.valid_acc, on_step=False, on_epoch=True, batch_size=batch.batch_size)\n",
        "\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        _, preds = self.forward(batch, mode=\"test\")\n",
        "        self.test_acc(preds, batch.y)\n",
        "        self.log('test_acc', self.test_acc, on_step=False, on_epoch=True, batch_size=batch.batch_size)\n",
        "        self.test_f1(preds, batch.y)\n",
        "        self.log('test_f1', self.test_f1, on_step=False, on_epoch=True, batch_size=batch.batch_size)\n",
        "        self.test_prec(preds, batch.y)\n",
        "        self.log('test_prec', self.test_prec, on_step=False, on_epoch=True, batch_size=batch.batch_size)\n",
        "        self.test_rec(preds, batch.y)\n",
        "        self.log('test_rec', self.test_rec, on_step=False, on_epoch=True, batch_size=batch.batch_size)"
      ],
      "metadata": {
        "id": "FwS0Crmc6XDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model training"
      ],
      "metadata": {
        "id": "RcTUrmDEr8N4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_graph_classifier(model_name, dataset, batch_size, feature, max_epochs, patience, **model_kwargs):\n",
        "    # Create a PyTorch Lightning trainer with the generation callback\n",
        "    root_dir = os.path.join(CHECKPOINT_PATH, \"GraphLevel\" + model_name)\n",
        "    os.makedirs(root_dir, exist_ok=True)\n",
        "\n",
        "    trainer = pl.Trainer(\n",
        "        default_root_dir=root_dir,\n",
        "        callbacks=[\n",
        "            ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"valid_acc\"),\n",
        "            EarlyStopping(monitor=\"valid_acc\", min_delta=0.00, patience=patience, verbose=True, mode=\"max\")],\n",
        "        accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
        "        devices=1,\n",
        "        max_epochs=max_epochs,\n",
        "        enable_progress_bar=False\n",
        "    )\n",
        "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
        "\n",
        "    dm = UPFDDataModule(\n",
        "        batch_size = batch_size,\n",
        "        dataset = dataset,\n",
        "        feature = feature\n",
        "    )\n",
        "    dm.setup(stage=\"fit\")\n",
        "\n",
        "    model = GraphLevelGNN(\n",
        "        model_name=model_name,\n",
        "        c_in=dm.num_node_features,\n",
        "        c_out=1 if dm.num_classes==2 else dm.num_classes,\n",
        "        **model_kwargs\n",
        "    )\n",
        "\n",
        "    trainer.fit(\n",
        "        model,\n",
        "        datamodule=dm\n",
        "    )\n",
        "    # Load and test best model\n",
        "    model = GraphLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
        "    dm.setup(stage=\"test\")\n",
        "    test_result = trainer.test(\n",
        "        model,\n",
        "        datamodule=dm,\n",
        "        verbose=True\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "7nuOOUvG6Yih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_graph_classifier(\n",
        "        model_name=\"hgpsl_gcn_pol\",\n",
        "        dataset=\"politifact\",\n",
        "        feature=\"bert\",\n",
        "        batch_size=128,\n",
        "        max_epochs=150,\n",
        "        patience=30,\n",
        "        learning_rate=1e-2,\n",
        "        conv_layer=\"gcn\",\n",
        "        c_hidden=128,\n",
        "        dropout_ratio=0.3,\n",
        "        pooling_ratio=0.3,\n",
        "        concat = False\n",
        "    )"
      ],
      "metadata": {
        "id": "PyMZnXWd6Zom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir=./saved_models/"
      ],
      "metadata": {
        "id": "KMskbSSjUrm3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}